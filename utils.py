#! /usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as onp
import jax.numpy as np
from typing import Callable


def C(n: int) -> onp.ndarray:
    """The C matrix defined in the text

    n: number of sampled haplotypes
    """
    W1 = onp.zeros((n - 1, n - 1))
    W2 = onp.zeros((n - 1, n - 1))
    b = onp.arange(1, n - 1 + 1)
    # j = 2
    W1[:, 0] = 6 / (n + 1)
    W2[:, 0] = 0
    # j = 3
    W1[:, 1] = 10 * (5 * n - 6 * b - 4) / (n + 2) / (n + 1)
    W2[:, 1] = (20 * (n - 2)) / (n+1) / (n+2)
    for col in range(n - 3):
        # this cast is crucial for floating point precision
        j = onp.float64(col + 2)
        # procedurally generated by Zeilberger's algorithm in Mathematica
        W1[:, col + 2] = -((-((-1 + j)*(1 + j)**2*(3 + 2*j)*(j - n)*(4 + 2*j - 2*b*j + j**2 - b*j**2 + 4*n + 2*j*n + j**2*n)*W1[:, col]) - (-1 + 2*j)*(3 + 2*j)*(-4*j - 12*b*j - 4*b**2*j - 6*j**2 - 12*b*j**2 - 2*b**2*j**2 - 4*j**3 + 4*b**2*j**3 - 2*j**4 + 2*b**2*j**4 + 4*n + 2*j*n - 6*b*j*n + j**2*n - 9*b*j**2*n - 2*j**3*n - 6*b*j**3*n - j**4*n - 3*b*j**4*n + 4*n**2 + 6*j*n**2 + 7*j**2*n**2 + 2*j**3*n**2 + j**4*n**2)*W1[:, col + 1])/(j**2*(2 + j)*(-1 + 2*j)*(1 + j + n)*(3 + b + j**2 - b*j**2 + 3*n + j**2*n)))
        W2[:, col + 2] = ((-1 + j)*(1 + j)*(2 + j)*(3 + 2*j)*(j - n)*(1 + j - n)*(1 + j + n)*W2[:, col] + (-1 + 2*j)*(3 + 2*j)*(1 + j - n)*(j + n)*(2 - j - 2*b*j - j**2 - 2*b*j**2 + 2*n + j*n + j**2*n)*W2[:, col + 1])/((-1 + j)*j*(2 + j)*(-1 + 2*j)*(j - n)*(j + n)*(1 + j + n))

    return W1 - W2


def M(n: int, t: np.ndarray, y: np.ndarray) -> np.ndarray:
    """The M matrix defined in the text

    t: time grid, starting at zero and ending at np.inf
    y: population size in each epoch
    """
    # epoch durations
    s = np.diff(t)
    # we handle the final infinite epoch carefully to facilitate autograd
    u = np.exp(-s[:-1] / y[:-1])
    u = np.concatenate((np.array([1]), u, np.array([0])))

    binom_vec = np.arange(2, n + 1) * (np.arange(2, n + 1) - 1) / 2

    return np.exp(binom_vec[:, np.newaxis]
                  * np.cumsum(np.log(u[np.newaxis, :-1]), axis=1)
                  - np.log(binom_vec[:, np.newaxis])) \
        @ (np.eye(len(y), k=0) - np.eye(len(y), k=-1)) \
        @ np.diag(y)


def prf(Z: np.ndarray, X: np.ndarray, L: np.ndarray) -> np.float64:
    u"""Poisson random field log-likelihood of history

    Z: mutation spectrum history matrix (μ.Z)
    X: k-SFS data
    L: model matrix
    """
    Ξ = L @ Z
    ℓ = (X * np.log(Ξ) - Ξ).sum()
    return ℓ


def d_kl(Z: np.ndarray, X: np.ndarray, L: np.ndarray) -> np.float64:
    u"""Kullback-Liebler divergence between normalized SFS and its
    expectation under history
    ignores constant term

    Z: mutation spectrum history matrix (μ.Z)
    X: k-SFS data
    L: model matrix
    """
    X_normalized = X / X.sum(axis=0)
    Ξ = L @ Z
    Ξ_normalized = Ξ / Ξ.sum(axis=1, keepdims=True)
    d_kl = (-X_normalized * np.log(Ξ_normalized)).sum()
    return d_kl


def lsq(Z: np.ndarray, X: np.ndarray, L: np.ndarray) -> float:
    u"""least-squares loss between SFS and its expectation under history

    Z: mutation spectrum history matrix (μ.Z)
    X: k-SFS data
    L: model matrix
    """
    Ξ = L @ Z
    lsq = (1 / 2) * ((Ξ - X) ** 2).sum()
    return lsq


def acc_prox_grad_descent(x: np.ndarray,
                          g: Callable[[np.ndarray], np.float64],
                          grad_g: Callable[[np.ndarray], np.float64],
                          h: Callable[[np.ndarray], np.float64],
                          prox: Callable[[np.ndarray, np.float64], np.float64],
                          tol: np.float64 = 1e-10,
                          max_iter: int = 100,
                          s0: np.float64 = 1,
                          max_line_iter: int = 100,
                          γ: np.float64 = 0.8) -> np.ndarray:
    u"""Nesterov accelerated proximal gradient descent

    x: initial point
    g: differential term in onjective function
    grad_g: gradient of g
    h: non-differentiable term in objective function
    prox: proximal operator corresponding to h
    tol: relative tolerance in objective function for convergence
    max_iter: maximum number of proximal gradient steps
    s0: initial step size
    max_line_iter: maximum number of line search steps
    γ: step size shrinkage rate for line search
    """
    # initialize step size
    s = s0
    # initialize momentum iterate
    q = x
    # initial objective value
    f = g(x) + h(x)
    print(f'initial cost {f:.6e}', flush=True)
    for k in range(1, max_iter + 1):
        # evaluate differtiable part of objective at momentum point
        g1 = g(q)
        grad_g1 = grad_g(q)
        # store old iterate
        x_old = x
        # Armijo line search
        for line_iter in range(max_line_iter):
            if not np.all(np.isfinite(grad_g1)):
                raise RuntimeError(f'invalid gradient at step {k + 1}, line '
                                   f'search step {line_iter + 1}: {grad_g1}')
            # new point via prox-gradient of momentum point
            x = prox(q - s * grad_g1, s)
            # G_s(q) as in the notes linked above
            G = (1 / s) * (q - x)
            # test g(q - sG_s(q)) for sufficient decrease
            if g(q - s * G) <= (g1 - s * (grad_g1 * G).sum()
                                + (s / 2) * (G ** 2).sum()):
                # Armijo satisfied
                break
            else:
                # Armijo not satisfied
                s *= γ  # shrink step size
        # update momentum term
        q = x + ((k - 1) / (k + 2)) * (x - x_old)
        if line_iter == max_line_iter - 1:
            print('warning: line search failed', flush=True)
            s = s0
        if not np.all(np.isfinite(x)):
            print(f'warning: x contains invalid values', flush=True)
        # terminate if objective function is constant within tolerance
        f_old = f
        f = g(x) + h(x)
        print(f'iteration {k}, cost {f:.6e}', end='        \r', flush=True)
        rel_change = np.abs((f - f_old) / f_old)
        if rel_change < tol:
            print(f'\nrelative change in objective function {rel_change:.2g} '
                  f'is within tolerance {tol} after {k} iterations',
                  flush=True)
            break
        if k == max_iter:
            print(f'\nmaximum iteration {max_iter} reached with relative '
                  f'change in objective function {rel_change:.2g}', flush=True)

    return x

def three_op_prox_grad_descent(x: np.ndarray,
                               g: Callable[[np.ndarray], np.float64],
                               grad_g: Callable[[np.ndarray], np.float64],
                               h: Callable[[np.ndarray], np.float64],
                               prox: Callable[[np.ndarray, np.float64],
                                              np.float64],
                               tol: np.float64 = 1e-10,
                               max_iter: int = 100,
                               s0: np.float64 = 1,
                               max_line_iter: int = 100,
                               γ: np.float64 = 0.8,
                               ls_tol: np.float64 = 0,
                               ρ: np.float64 = 1) -> np.ndarray:
    u"""Three operator splitting proximal gradient descent

    We implement the method of Pedregosa & Gidel (ICML 2018),
    including backtracking line search.

    The optimization problem solved is:

      min_x g(x) + h(x)
      s.t. x >= 0

    where g is differentiable, and prox_h is available.
    In this problem, we use prox_h as well as the projection onto
    the nonnegative orthant, for the constraint, as our prox operators.

    x: initial point
    g: differential term in objective function
    grad_g: gradient of g
    h: non-differentiable term in objective function
    prox: proximal operator corresponding to h
    tol: relative tolerance in objective function for convergence
    max_iter: maximum number of proximal gradient steps
    s0: step size
    max_line_iter: maximum number of line search steps
    γ: step size shrinkage rate for line search
    ls_tol: line search tolerance
    """
    assert np.all(x >= 0), 'initial x must be in nonnegative orthant'

    # initial objective value
    s = s0
    z = x
    u = np.zeros_like(z)
    f = g(x) + h(x)
    print(f'initial cost {f:.6e}', flush=True)

    for k in range(1, max_iter + 1):
        # evaluate differentiable part of objective
        g1 = g(z)
        grad_g1 = grad_g(z)
        if not np.all(np.isfinite(grad_g1)):
            raise RuntimeError(f'invalid gradient at step {k + 1}, line '
                                   f'search step {line_iter + 1}: {grad_g1}')
        # store old iterate
        # x_old = x
        # Armijo line search
        for line_iter in range(max_line_iter):
            # new point via prox-gradient of momentum point
            x = prox(z - s * (u + grad_g1), s)
            # quadratic approximation of cost
            Q = (g1 + (grad_g1 * (x - z)).sum()
                  + ((x - z) ** 2).sum() / (2 * s))
            if g(x) - Q <= ls_tol:
                # sufficient decrease satisfied
                break
            else:
                # sufficient decrease not satisfied
                s *= γ  # shrink step size
        if line_iter == max_line_iter - 1:
            print('warning: line search failed', flush=True)

        # update z variables: threshold to zero
        z = np.maximum(x + s * u, 0)
        # update u variables: dual variables
        u = u + (x - z) / s
        # grow step size
        s = min(s / γ**2, s0)

        # TODO: convergence based on dual certificate
        if not np.all(np.isfinite(x)):
            print(f'warning: x contains invalid values', flush=True)
        if np.any(x < 0):
            print(f'warning: x contains negative values', flush=True)
        # terminate if objective function is constant within tolerance
        f_old = f
        f = g(z) + h(z)
        print(f'iteration {k}, cost {f:.6e}', end='        \r', flush=True)
        rel_change = np.abs((f - f_old) / f_old)
        if rel_change < tol:
            print(f'\nrelative change in objective function {rel_change:.2g} '
                  f'is within tolerance {tol} after {k} iterations',
                  flush=True)
            break
        # if certificate < tol:
        #     print(f'certificate norm {certificate:.2g} '
        #           f'is within tolerance {tol} after {k} iterations')
        #     break
        if k == max_iter:
            print(f'\nmaximum iteration {max_iter} reached with relative '
                  f'change in objective function {rel_change:.2g}', flush=True)

    return z

# def three_op_prox_grad_descent(x: np.ndarray,
#                                g: Callable[[np.ndarray], np.float64],
#                                grad_g: Callable[[np.ndarray], np.float64],
#                                h: Callable[[np.ndarray], np.float64],
#                                prox: Callable[[np.ndarray, np.float64],
#                                               np.float64],
#                                tol: np.float64 = 1e-10,
#                                max_iter: int = 100,
#                                s0: np.float64 = 1,
#                                max_line_iter: int = 100,
#                                γ: np.float64 = 0.8,
#                                ls_tol: np.float64 = 0,
#                                ρ: np.float64 = 1) -> np.ndarray:
#     u"""Three operator splitting proximal gradient descent

#     We implement the method of Davis & Yin (arXiv, 2015),
#     including backtracking line search.

#     The optimization problem solved is:

#       min_x f(x)
#       s.t. x >= 0

#     where f(x) = g(x) + h(x), g is differentiable, and prox_h is available.
#     In this problem, we use prox_h as well as the projection onto
#     the nonnegative orthant as our two prox operators.

#     x: initial point
#     g: differential term in objective function
#     grad_g: gradient of g
#     h: non-differentiable term in objective function
#     prox: proximal operator corresponding to h
#     tol: relative tolerance in objective function for convergence
#     max_iter: maximum number of proximal gradient steps
#     s0: step size
#     max_line_iter: maximum number of line search steps
#     γ: step size shrinkage rate for line search
#     ls_tol: line search tolerance
#     """
#     assert np.all(x >= 0), 'initial x must be in nonnegative orthant'

#     # initial objective value
#     f = g(x) + h(x)
#     ρ = 1
#     print(f'initial cost {f:.6e}', flush=True)

#     for k in range(1, max_iter + 1):
#         xB = np.maximum(x, 0)
#         # evaluate differentiable part of objective
#         g1 = g(xB)
#         grad_g1 = grad_g(xB)
#         # store old iterate
#         # x_old = x
#         # Armijo line search
#         for line_iter in range(max_line_iter):
#             if not np.all(np.isfinite(grad_g1)):
#                 raise RuntimeError(f'invalid gradient at step {k + 1}, line '
#                                    f'search step {line_iter + 1}: {grad_g1}')
#             # new point via prox-gradient of momentum point
#             xA = prox(xB + ρ * (xB - x) - ρ * s0 * grad_g1, ρ * s0)
#             # Qt
#             Qt = (g1 + (grad_g1 * (xA - xB)).sum()
#                   + ((xA - xB) ** 2).sum() / (2 * ρ * s0))
#             if g(xA) - Qt <= ls_tol:
#                 # sufficient decrease satisfied
#                 break
#             else:
#                 # sufficient decrease not satisfied
#                 ρ *= γ  # shrink step size
#         if line_iter == max_line_iter - 1:
#             print('warning: line search failed', flush=True)

#         # new iterate
#         x = x + xA - xB
#         # # averaging
#         # x = x + ((k - 1) / (k + 2)) * (x - x_old)
#         # grow step size a little bit
#         ρ = 1

#         if not np.all(np.isfinite(x)):
#             print(f'warning: x contains invalid values', flush=True)
#         if np.any(x < 0):
#             print(f'warning: x contains negative values', flush=True)
#         # terminate if objective function is constant within tolerance
#         f_old = f
#         f = g(x) + h(x)
#         print(f'iteration {k}, cost {f:.6e}', end='        \r', flush=True)
#         rel_change = np.abs((f - f_old) / f_old)
#         if rel_change < tol:
#             print(f'\nrelative change in objective function {rel_change:.2g} '
#                   f'is within tolerance {tol} after {k} iterations',
#                   flush=True)
#             break
#         # if certificate < tol:
#         #     print(f'certificate norm {certificate:.2g} '
#         #           f'is within tolerance {tol} after {k} iterations')
#         #     break
#         if k == max_iter:
#             print(f'\nmaximum iteration {max_iter} reached with relative '
#                   f'change in objective function {rel_change:.2g}', flush=True)

#     return x
