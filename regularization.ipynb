{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing regularization approaches\n",
    "\n",
    "Here's a notebook for playing with different penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt\n",
    "from dement import DemEnt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize, check_grad\n",
    "from scipy.special import erf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a model\n",
    "--\n",
    "We'll simulate a demographic history that suffers a crash then an exponential recovery\n",
    "\n",
    "Define the time axis $\\mathbf{t}$ (including the boundary at infinity) and the population size trajectory $\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([0] + list(np.logspace(0, 4, 100)) + [np.inf])\n",
    "\n",
    "# constant\n",
    "# y_true = 10000 * np.ones(len(t) - 1)\n",
    "\n",
    "# crash followed by exponential growth\n",
    "y_true = 1000 * (10 * np.exp(-t[:-1]/100) + 1 + 5 * np.array(t[:-1] > 1000, float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of sampled haplotypes $n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize dement object, and print its docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dement = DemEnt(n, t, y_true)\n",
    "print(dement.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inversion\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization with constant model\n",
    "\n",
    "We initialize by fitting a constant population size.\n",
    "According to WSD's scribbles, the MLE assuming $\\eta(t) = \\eta_0$ (constant) is $\\hat \\eta_0 = \\frac{S}{2 H_{n-1}}$, where $S$ is the number of segregating sites (the sum of the observed SFS vector) and $H_{n-1}$ is the $n$th harmonic number.\n",
    "This was derived by using the well-known result (cited in Rosen et al.) that the expected SFS for a constant population is given by $\\xi_i = \\frac{2\\eta_0}{i}$ (in units where $\\eta$ is the population-scaled mutation rate).\n",
    "Then the likelihood for $\\eta_0$ is a Poisson random field parameterized by the $\\xi_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = dement.sfs.sum()\n",
    "H = (1 / np.arange(1, len(dement.sfs))).sum()\n",
    "y_constant = (S / 2 / H) * np.ones(len(t) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized loss as a penalized log-likelihood\n",
    "We must deal with the asymptotically constant boundary condition.\n",
    "Standard regularizers blow up on the infinite epoch.\n",
    "Let's use Gaussian instead of Lebesgue measure on time to induce integrability: $\\mathrm{d}\\mu(t) = \\exp\\left(-\\frac{1}{2}\\left(\\frac{t}{\\tau}\\right)^2\\right)\\mathrm{d}t,$\n",
    "where $\\tau$ is the characteristic time to asmptopia (the boundary of our time grid).\n",
    "For example, a modified $L2$ would be\n",
    "$$\n",
    "R\\left[\\eta(t)\\right] = \\int_0^\\infty \\eta(t)^2 \\mathrm{d}\\mu(t) = \\int_0^\\infty \\eta(t)^2 \\exp\\left(-\\frac{1}{2}\\left(\\frac{t}{\\tau}\\right)^2\\right)\\mathrm{d}t.\n",
    "$$\n",
    "So the discretized problem is expressed in terms of the error function $\\DeclareMathOperator{\\erf}{erf}\\erf(\\cdot)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_prime, lambda_: float):\n",
    "    # gaussian transformed measure\n",
    "    tau = 10 * dement.t[-2]\n",
    "    dmu = np.diff(erf(dement.t / tau / np.sqrt(2))) * tau * np.sqrt(np.pi / 2)\n",
    "    # generalized KL divergence (a Bregman divergence)\n",
    "    R = ((y * np.log(y/y_prime) - y + y_prime) * dmu).sum()\n",
    "    # fusion L2\n",
    "#     R = ((np.diff(y) * dmu[:-1])**2).sum()\n",
    "    return - dement.ell(y) + lambda_ * R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize loss with L-BFGS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial regularization strength\n",
    "lambda_ = 1e1\n",
    "\n",
    "# initial and prior\n",
    "y = y_constant\n",
    "y_prime = y_constant\n",
    "\n",
    "for _ in range(10):\n",
    "    result = minimize(loss,\n",
    "                      y,\n",
    "                      args=(y_prime, lambda_),\n",
    "                      # jac=gradF,\n",
    "                      method='L-BFGS-B',\n",
    "                      options=dict(\n",
    "    #                                ftol=1e-10,\n",
    "                                   maxfun=np.inf),\n",
    "                      bounds=[(1e-6, None)] * len(y))\n",
    "    assert result.success, result\n",
    "    y = result.x\n",
    "    \n",
    "    dement.plot(y, y_label='inferred ($\\lambda = ${:.2g})'.format(lambda_))    \n",
    "    \n",
    "    # update prior and reduce regularization strength\n",
    "    y_prime = y\n",
    "    lambda_ /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
