#! /usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
from scipy.special import binom
from functools import lru_cache
from scipy.stats import poisson
from scipy.special import gammaln
from matplotlib import pyplot as plt
from scipy.optimize import minimize


class History():
    '''piecewise constant history of population size η and mutation rate μ
    '''

    def __init__(self, t: np.array,
                 y: np.ndarray = None, z: np.ndarray = None):
        '''
        t: The time axis, given as epoch change points. The first epoch starts
           at zero, and the last epoch extends to infinity
        y: vector of constant η(t) pieces
        z: vector of constant μ(t) pieces
        '''
        if any(np.diff(t) <= 0) or np.isinf(t).sum() or any(t <= 0):
            raise ValueError('t must be increasing, finite, and positive')
        self.t = np.concatenate(([0], t, [np.inf]))
        self.m = len(self.t) - 1
        if y is not None:
            if len(y) != len(t) + 1:
                raise ValueError(f'len(t) = {len(t)} implies {len(t) + 1} '
                                 f'epochs, but len(y) = {len(y)}')
            if any(y <= 0) or np.isinf(y).sum():
                raise ValueError('elements of y must be finite and positive')
            self.y = y
        else:
            self.y = None
        if z is not None:
            if len(z) != len(t) + 1:
                raise ValueError(f'len(t) = {len(t)} implies {len(t) + 1} '
                                 f'epochs, but len(z) = {len(z)}')
            if any(z <= 0) or np.isinf(z).sum():
                raise ValueError('elements of z must be finite and positive')
            self.z = z
        else:
            self.z = None

    def η(self):
        return History(self.t[1:-1], y=self.y)

    def μ(self):
        return History(self.t[1:-1], z=self.z)


class SFS():
    '''The SFS model described in the text
    '''

    def __init__(self, n: int = None, sfs: np.ndarray = None):
        '''
        pass one of these arguments
        n: number of sampled haplotypes
        sfs: observed sfs vector
        '''
        if sfs is not None:
            self.sfs = sfs
            self.n = len(sfs) + 1
            assert n is None, 'pass only one of n or sfs'
        elif n is not None:
            self.sfs = None
            self.n = n
            assert sfs is None, 'pass only one of n or sfs'
        else:
            raise ValueError('must pass either n or sfs')
        if self.n < 2:
            raise ValueError('n must be larger than 1')
        self._binom_vec = binom(np.arange(2, self.n + 1), 2)
        self._binom_array_recip = np.diag(1 / self._binom_vec)
        self.C = SFS.C(self.n)

    @staticmethod
    def W1(n: int) -> np.ndarray:
        '''The W1 matrix defined in the text

        n: number of sampled haplotypes
        '''
        W1 = np.zeros((n - 1, n - 1))
        b = np.arange(1, n - 1 + 1)
        # j = 2
        W1[:, 0] = 6 / (n + 1)
        # j = 3
        W1[:, 1] = 10 * (5 * n - 6 * b - 4) / (n + 2) / (n + 1)
        for j in range(2, n - 1):
            col = j - 2
            # procedurally generated by Zeilberger's algorithm in Mathematica
            W1[:, col + 2] = -((-((-1 + j)*(1 + j)**2*(3 + 2*j)*(j - n)*(4 + 2*j - 2*b*j + j**2 - b*j**2 + 4*n + 2*j*n + j**2*n)*W1[:, col]) - (-1 + 2*j)*(3 + 2*j)*(-4*j - 12*b*j - 4*b**2*j - 6*j**2 - 12*b*j**2 - 2*b**2*j**2 - 4*j**3 + 4*b**2*j**3 - 2*j**4 + 2*b**2*j**4 + 4*n + 2*j*n - 6*b*j*n + j**2*n - 9*b*j**2*n - 2*j**3*n - 6*b*j**3*n - j**4*n - 3*b*j**4*n + 4*n**2 + 6*j*n**2 + 7*j**2*n**2 + 2*j**3*n**2 + j**4*n**2)*W1[:, col + 1])/(j**2*(2 + j)*(-1 + 2*j)*(1 + j + n)*(3 + b + j**2 - b*j**2 + 3*n + j**2*n)))
        return W1

    @staticmethod
    def W2(n: int) -> np.ndarray:
        '''The W2 matrix defined in the text

        n: number of sampled haplotypes
        '''
        W2 = np.zeros((n - 1, n - 1))
        b = np.arange(1, n - 1 + 1)
        # j = 2
        W2[:, 0] = 0
        # j = 3
        W2[:, 1] = (20 * (n - 2)) / (n+1) / (n+2)
        for j in range(2, n - 1):
            col = j - 2
            # procedurally generated by Zeilberger's algorithm in Mathematica
            W2[:, col + 2] = ((-1 + j)*(1 + j)*(2 + j)*(3 + 2*j)*(j - n)*(1 + j - n)*(1 + j + n)*W2[:, col] + (-1 + 2*j)*(3 + 2*j)*(1 + j - n)*(j + n)*(2 - j - 2*b*j - j**2 - 2*b*j**2 + 2*n + j*n + j**2*n)*W2[:, col + 1])/((-1 + j)*j*(2 + j)*(-1 + 2*j)*(j - n)*(j + n)*(1 + j + n))
        return W2

    @staticmethod
    def C(n: int) -> np.ndarray:
        '''The C matrix defined in the text

        n: number of sampled haplotypes
        '''
        return SFS.W1(n) - SFS.W2(n)

    @lru_cache(maxsize=1)
    def M(self, history: History) -> np.ndarray:
        '''The M matrix defined in the text
        '''
        # epoch durations
        s = np.diff(history.t)
        u = np.exp(-s / history.y)
        u = np.insert(u, 0, 1)

        return self._binom_array_recip \
               @ np.cumprod(u[np.newaxis, :-1], axis=1) ** self._binom_vec[:, np.newaxis] \
               @ (np.eye(history.m, k=0) - np.eye(history.m, k=-1)) \
               @ np.diag(history.y)

    @lru_cache(maxsize=1)
    def Γ(self, history: History, h: np.float = 1) -> np.ndarray:
        '''The Gamma matrix defined in the text

        h: relative increase in penalty as we approach coalescent horizon
        '''
        # epoch durations
        s = np.diff(history.t)
        u = np.exp(-s / history.y)
        u = np.insert(u, 0, 1)

        # the A_2j product of these terms
        l = np.array(range(2, self.n + 1))[:, np.newaxis]
        with np.errstate(divide='ignore'):
            A2_terms = l * (l-1) / (l * (l-1) - l.T * (l.T-1))
        np.fill_diagonal(A2_terms, 1)
        A2 = np.prod(A2_terms, axis=0)

        return (np.diag(np.insert(h * np.ones(history.m - 1), 0, h - 1)) + (1 - h)
                * np.diagflat(A2[np.newaxis, :]
                          @ np.cumprod(u[np.newaxis, :-1],
                                       axis=1) ** self._binom_vec[:, np.newaxis])) \
               @ (np.eye(history.m, k=0) - np.eye(history.m, k=-1))

    def ξ(self, history: History) -> np.ndarray:
        '''expected sfs vector
        '''
        return self.C @ self.M(history.η()) @ history.z

    def simulate(self, history: History) -> None:
        '''simulate a SFS under the Poisson random field model (no linkage)
        '''
        self.sfs = poisson.rvs(self.ξ(history))

    def ℓ(self, history: History) -> np.float:
        '''Poisson random field log-likelihood of history
        '''
        if self.sfs is None:
            raise ValueError('use simulate() to generate data first')
        ξ = self.ξ(history)
        return (self.sfs * np.log(ξ) - ξ - gammaln(self.sfs + 1)).sum()

    def L(self, history: History,
             λ_η: np.float = 0, λ_μ: np.float = 0,
             h: np.float = 1) -> np.float:
        '''loss: negative log likelihood (Poisson random field) and regularization
        as described in the text

        λ_η: regularization strength on η
        λ_μ: regularization strength on μ
        h: relative increase in penalty as we approach coalescent horizon
        '''
        Γ = self.Γ(history.η(), h)
        ρ_η = ((Γ @ history.y)**2).sum()
        # ρ_μ = ((np.diff(history.z))**2).sum()
        # ρ_μ = (history.z**2).sum()
        # ρ_μ = (np.abs(np.diff(history.z))).sum()
        ρ_μ = ((Γ @ history.z)**2).sum()
        return -self.ℓ(history) + λ_η * ρ_η + λ_μ * ρ_μ

    def infer_μ(self, history: History, λ_μ: np.float = 0, h: np.float = 1):
        '''infer the μ history given the simulated sfs and η history

        history: initial history
        λ_μ: regularization strength
        h: relative increase in penalty as we approach coalescent horizon
        '''
        def f(z) -> np.float:
            _history = history
            _history.z = z
            return self.L(_history, λ_η=0, λ_μ=λ_μ, h=h)

        result = minimize(f,
                          history.z,
                          # jac=gradF,
                          method='L-BFGS-B',
                          options=dict(
                                       # ftol=1e-10,
                                       maxfun=np.inf
                                       ),
                          bounds=[(1e-10, None)] * history.m
                          )
        if not result.success:
            raise ValueError(result.message)
        else:
            history.z = result.x
            return history

    #
    # def plot(self, history) -> None:
    #     '''plot the true η(t), and optionally a fitted one y if self.y_inferred
    #     is not None
    #     '''
    #     fig, axes = plt.subplots(1, 2, figsize=(7, 3))
    #     axes[0].step(self.t[:-1], self.y_true, 'k', where='post', label='true')
    #     if hasattr(self, 'y_inferred'):
    #         axes[0].step(self.t[:-1], self.y_inferred, 'r', where='post',
    #                      label='inverted')
    #     if hasattr(self, '_λ_diff'):
    #         ax_right = axes[0].twinx()
    #         ax_right.set_ylabel('$\\λ_{\\eta\'}$', color='tab:blue')
    #         ax_right.plot(self.t, λ_diff, 'tab:blue')
    #         ax_right.tick_params(axis='y', labelcolor='tab:blue')
    #         ax_right.set_yscale('log')
    #     axes[0].set_xlabel('$t$')
    #     axes[0].set_ylabel('$\\eta(t)$')
    #     axes[0].legend()
    #     axes[0].legend(loc=0)
    #     axes[0].set_ylim([0, None])
    #     axes[0].set_xscale('symlog')
    #     # axes[0].set_yscale('log')
    #
    #     if hasattr(self, 'y_inferred'):
    #         xi = self.xi(self.y_inferred)
    #         xi_lower = poisson.ppf(.025, xi)
    #         xi_upper = poisson.ppf(.975, xi)
    #         axes[1].plot(range(1, len(xi) + 1), xi, 'r--', label=r'$\xi$')
    #         axes[1].fill_between(range(1, len(xi) + 1),
    #                              xi_lower, xi_upper,
    #                              facecolor='r', alpha=0.25,
    #                              label='inner 95%\nquantile')
    #     axes[1].plot(range(1, len(self.sfs) + 1), self.sfs,
    #                  'k.', alpha=.25, label=r'simulated')
    #     axes[1].set_xlabel('$i$')
    #     axes[1].set_ylabel(r'$\xi_i$')
    #     axes[1].set_xscale('log')
    #     axes[1].set_yscale('symlog')
    #     axes[1].legend()
    #     axes[1].legend(loc=0)
    #
    #     plt.tight_layout()
    #     plt.show()
