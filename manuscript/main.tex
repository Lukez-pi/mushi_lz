\documentclass[11pt]{article}

\usepackage{fullpage}
\usepackage[round,semicolon]{natbib}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}

\DeclareMathOperator{\erf}{erf}
\DeclareMathOperator{\lngamma}{\ln\!\Gamma}
\DeclareMathOperator{\Tr}{Tr}

% NOTE
% one sentence per line for nice git diffs
% WD: I'm a fan of initialed source comments like this

\title{Coalescent inference of mutation spectrum histories from sample frequency spectra}

\author{
W.S. DeWitt$^{1,4}$, K. Decker Harris$^{2,3}$, and K. Harris$^{1}$\\
{\small
$^1$Department of Genome Sciences,
$^2$Paul G.\ Allen School of Computer Science \& Engineering,}\\
{\small and $^3$Department of Biology, University of Washington, Seattle, WA}\\
{\small $^4$Computational Biology Program, Fred Hutchinson Cancer Research Center, Seattle, WA}
% \small{$^\ast$ Equal contribution}
}

\begin{document}

\maketitle

\begin{abstract}

Single nucleotide variant (SNV) frequencies partitioned according to local nucleotide context vary among human ancestry groups and among great ape species, indicating variation and divergence of the mutation process.
The sample frequency spectrum (SFS)---the distribution of derived allele frequencies among sampled haplotypes---is a well-studied population genetic summary statistic that is sensitive to demographic history.
We extend a coalescent framework for demographic inference from the SFS to accommodate inference of mutation spectrum histories from the sample frequency spectrum resolved by $k$-mer nucleotide context ($k$-SFS).
We formulate inference of mutation spectrum histories from the $k$-SFS as a linear inverse problem.

\end{abstract}


\section*{Introduction}\label{sec:intro}

\cite{Harris2017-fw} showed triplet SNV spectrum differences between human groups and between great apes, and used a coalescent simulation approach to fit the timing of a pulse of \texttt{T\underline{C}C>T\underline{T}C} mutations in Europeans.
We develop coalescent theory for the dependence of the expected $k$-SFS on both demographic history (effective population size as a function of time into the past) \emph{and} mutation spectrum history (mutation intensities as a function of time into the past for each mutation type).
This is similar in spirit to Kelley's simulation-based approach (which assumed the European demography of \cite{Tennessen2012-dq}), but is much faster, more flexibly parameterized.

Some references for nonidentifiability of demographic history from the SFS: \cite{Baharian2018-np, Bhaskar2014-fu, Terhorst2015-xt, Myers2008-jp}.
It might be good to consider identifiability of mutation intensity history from the SFS conditioned on demographic history.

%WD todo: inverse problem intro, forward Vs inverse problems, and ill-posedness. Point out \eta is nonlinear, but \mu is linear

%WD todo: the scope of this paper is \mu inference conditioned on \eta. There are plenty of fancy methods one can use to infer \eta

Humblebrag: the word \emph{spectrum} is triply overloaded in this paper:
\begin{enumerate}
\item the traditional sample frequency \emph{spectrum}
\item mutation \emph{spectrum} as in the nucleotide context of each mutation
\item \emph{spectral} regularization for encouraging low rank solutions
\end{enumerate}

\section*{Model}\label{sec:model}

The setting for our modeling is Kingman's coalescent \citep{Kingman1982-ge, Kingman1982-tf, Kingman1982-ys, Kingman2000-jr}, with all the usual niceties: neutrality, infinite sites, linkage equilibrium, and panmixia.
In Appendix \ref{sec:appendix} we detail our retracing of the derivation by \cite{Griffiths1998-qf} of the frequency distribution of a derived allele conditioned on the demographic history, while generalizing to a time inhomogeneous mutation process.
We make use of the results of \cite{Polanski2003-kg} and \cite{Polanski2003-ll} to facilitate computation, and build on the notation of \cite{Rosen2018-bb} for a finite-dimensional approximation of our demographic and mutation intensity histories.
Complete derivation of formulae are found in the Appendix.

Given $n$ sampled haplotypes and a demographic history $\eta(t)$ (with time measured retrospectively from the present), we show in Appendix \ref{sec:appendix:xi} that the expected SFS $\boldsymbol \xi = (\xi_1, \xi_2,\dots, \xi_{n-1})$ is a linear transform of the mutation intensity history $\mu(t)$:
\begin{equation}
  \label{eqn:transform}
\boldsymbol \xi = \mathcal{L}_{n,\eta(t)}\mu(t),
\end{equation}
where $\mathcal{L}_{n,\eta(t)}$ is a finite-rank linear operator that maps infinite-dimensional mutation intensity histories to $(n-1)$-dimensional SFS vectors.
It is dependent on $n$ and $\eta$, which we take to be fixed.

% Need to talk about this fig \ref{fig:model}.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{figures/model}
\caption{Schematic of the marked Poisson process model with $n=4$.
We condition on coalescent times $T_4=t_4,T_3=t_3,T_2=t_2$ and consider mutation intensity function $\mu(t)$.
Red dots indicate mutation events placed by time $t$, genomic position $x$, and coalescent line (which are depicted as extruded in the genomic coordinate axis, grey sheets).
The probability that a differential element $dxdt$ on a given sheet contains a mutation is proportional to the instantaneous mutation intensity $\mu(t)$.
}
\label{fig:model}
\end{figure}

In previous work \citep{Kelley, cancer, etc}, mutation spectra have been parameterized by grouping variants into mutation types according to local $k$-mer nucleotide context, and the number of variants called in each mutation type is taken as a proxy integrating an individual's ancestral mutational input in each type.
With $k$ odd and the variant registered in the central position there are $\kappa_k=2\times3\times4^{k-1}$ mutation types after collapsing by strand symmetry.
For example, there are $96$ triplet mutation types ($k=3$).
Here, we use the same $k$-mer mutation type parameterization to promote the $(n-1)$-element expected SFS vector $\xi$ to the $(n-1)\times\kappa_k$ expected $k$-SFS matrix $\Xi$.
Similarly, the mutation intensity history function $\mu(t)$ is promoted to the $\kappa_k$-element mutation spectrum history $\boldsymbol\mu(t)$, with each element giving the mutation intensity history function for one mutation type.
Equation \eqref{eqn:transform} becomes
\begin{equation}
  \label{eqn:transform_matrix}
\Xi = \mathcal{L}_{n,\eta(t)}\boldsymbol\mu^\intercal(t),
\end{equation}

For numerical implementation we consider finite-dimensional approximations of $\eta(t)$ and $\boldsymbol\mu(t)$ as piecewise constant functions of time on $m$ common epochs $[t_0, t_1), [t_1, t_2),\dots, [t_{m-1}, t_m)$ where $0=t_0 < t_1 < \dots < t_{m-1} < t_m=\infty$.
We take the epoch boundaries as fixed parameters, and in practice make them dense so as to approximate infinite-dimensional histories.
Let $\boldsymbol y = (y_1,\dots,y_m)$ denote the constant population size $\eta(t)$ during each epoch, and let the $m\times\kappa_k$ matrix $Z$ denote the constant mutation intensity during each epoch (rows) for each mutation type (columns).
In Appendix \ref{sec:appendix:pcsws} we show the linear transform \eqref{eqn:transform_matrix} reduces to the matrix equation
\begin{equation}
\label{eqn:transform_discrete}
\Xi = L_{n, \boldsymbol y} Z,
\end{equation}
where the $(n-1)\times m$ matrix $L_{n, \boldsymbol y}$ is fixed given a fixed demographic history $\boldsymbol y$.

In linkage equilibrium the log likelihood function of the mutation spectrum history $Z$ given an observed $k$-SFS matrix $X$ and demographic history $\boldsymbol y$ is given by the Poisson random field approximation \citep{}
\[
\ell(Z; X, \boldsymbol y, n) = \Tr(X^\intercal\log(L_{n, \boldsymbol y} Z)) - \|L_{n, \boldsymbol y} Z\|_1,
\]
where $\log(\cdot)$ operates elementwise, and we've dropped a constant term wrt $Z$.

%WD more inverse problem intro
The inverse problem \eqref{eqn:transform_discrete} is ill-posed in general, 
so many very different histories can be equally consistent with the data 
\citep{oscillation paper? Yun's other papers?}.
We deal with this problem using regularization, to enforce well-behaved histories.
Our cost function to minimize, a penalized log-likelihood, is
\begin{equation}
\label{eqn:penalized}
C(Z)
%\tilde\ell(\boldsymbol z)
= -\ell(Z) + R(Z) .
\end{equation}
The function $R(Z)$ incorporates our regularization.
In order to recover smooth histories,
we penalize the $L^p$ norms
of the time derivative of $\boldsymbol\mu(t)$
\[
\sum_{i=1}^{\kappa_k}\left\| \frac{d \mu_i(t)}{d t} \right\|_p^p
= \sum_{i=1}^{\kappa_k}\int_0^\infty\left|\frac{d\mu_i(t)}{dt}\right|^p dt,
\]
for $p=1,2$.
With piecewise constant histories as in \eqref{eqn:transform_discrete} this becomes
\[
\left\|\Delta Z \right\|_p^p.
\]
where $\Delta$ denotes the first difference matrix.
When $p = 1$, this is referred to as a fused LASSO or total variation (TV) penalty,
whereas $p=2$ is called a spline penalty.
We have implemented three different types of regularization.

The first option we call ``soft'' rank regularization, with 
\begin{equation}
  \label{eq:regularization_soft}
  R_\mathrm{soft}(Z) 
  = 
  \frac{  \lambda_\mathrm{spline} }{2} \left\|\Delta Z\right\|_2^2
  +
  \lambda_\mathrm{rank} \| Z \|_*
  +
   \frac{\lambda_\mathrm{ridge}}{2}  \| Z \|_\mathrm{F}^2
   .
\end{equation}
The spline term controls the smoothness of solutions, 
and the rank term allows us to recover low-rank solutions.
The rank penalty is the nuclear norm $\| Z \|_*$, 
which is equivalent to the $\ell^1$-norm on the singular values.
If $Z = U S V^\intercal$ is the SVD of $Z$, with $S = \mathrm{diag}(\sigma)$ then $\| Z \|_* = \| \sigma \|_1$.
The parameters $\lambda_\mathrm{spline}$ and $\lambda_\mathrm{rank}$ control the overall strength
of smoothing and rank regularization.
The function $R_\mathrm{soft}$ is convex; therefore we have a convex optimization problem 
in this scenario.

The second option is ``hard'' rank regularization, where
\begin{equation}
  \label{eq:regularization_soft}
  R_\mathrm{hard}(Z) 
  = 
  \frac{\lambda_\mathrm{spline}}{2} \left\|\Delta Z\right\|_2^2
  +
  \lambda_\mathrm{rank} \, \mathrm{rank}(Z)
  +
  \frac{\lambda_\mathrm{ridge}}{2} \| Z \|_\mathrm{F}^2
  .
\end{equation}
Here, the rank penalty is the actual rank of $Z$,
and note that $\mathrm{rank}(Z) = \| \sigma \|_0$.
In this case the problem is {\em not} convex.
However, we may still compute a proximal map for the non-differentiable rank term
and optimize with prox-gradients.

The third option allows more general smoothing but ignores all rank penalization:
\begin{equation}
  \label{eq:regularization_soft}
  R_\mathrm{indep}(Z) 
  = 
  \lambda_\mathrm{TV} 
  \left\|\Delta Z\right\|_1 
  + 
  \frac{\lambda_\mathrm{spline}}{2} \left\|\Delta Z\right\|_2^2
  +
  \frac{\lambda_\mathrm{ridge}}{2} \| Z \|_\mathrm{F}^2
  .
\end{equation}
The TV terms control the smoothness of solutions, 
and the rank term allows us to recover low-rank solutions.
The function $R_\mathrm{indep}$ is convex.
Note also that the columns of $Z$ are uncoupled, 
so that we may solve this case as $\kappa_k$ different subproblems.


\section*{Results}\label{sec:results}

% Todo:
% \begin{itemize}
% \item repeat 1KG analysis like in \cite{Harris2017-fw}, see if we recapitulate Kelley's simulation-based pulse results
% \item cluster triplet time series to see if we pull in minor components.
% \end{itemize}

\begin{figure}
  \centering
  \includegraphics[width=.7\textwidth]{figures/fit_teaser}
  \caption{Simulating and inverting a pulse.}
  \label{}
\end{figure}

\subsection*{Tempora incognita: observability toward the coalescent horizon}\label{sec:model:loss}

Todo: SVD on $L_{n, \boldsymbol y}$

Intuitively, we know the SFS can't contain any information about the history beyond the TMRCA $T_2$, since mutations that occurred before then will not be segregating in the sample.
Thus, we will find it useful to penalize complexity in the history more heavily at times that are more probably ancestral to the TMRCA.

From \eqref{eqn:pi} and \eqref{eqn:r} in the Appendix \ref{sec:appendix}, the CDF of $T_2$ is
\begin{align}
F_2(t) &= 1 - \sum_{j=2}^n A_{2,j}r_2(t)\\
&= 1 - \sum_{j=2}^n A_{2,j}r_2(t)
\end{align}


\section*{Discussion}\label{sec:discussion}

Joint inference of $\eta$ and $\mu$.


\section*{Methods}\label{sec:methods}

\subsection*{Implementation and pipeline}\label{sec:methods:tool}

The \texttt{mushi} software package is available at \url{https://github.com/harrispopgen/mushi}.
%WD cite whatever packages we use, e.g. proxtv, msprime, stdpopsim, etc.

\section*{Acknowledgements}\label{sec:ack}

\bibliographystyle{plainnat}
\bibliography{refs}


\appendix
\input{appendix}


\end{document}
